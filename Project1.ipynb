{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from tensorflow import keras\n",
    "from keras.utils import pad_sequences\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical, pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from Hugging Face\n",
    "dataset =pd.read_parquet(\"hf://datasets/thesven/Reflective-MAGLLAMA-v0.1/data/train-00000-of-00001.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10227 entries, 0 to 10226\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   instruction          10227 non-null  object\n",
      " 1   model_name           10227 non-null  object\n",
      " 2   generation           10227 non-null  object\n",
      " 3   distilabel_metadata  10227 non-null  object\n",
      " 4   text                 10227 non-null  object\n",
      " 5   embedding            10227 non-null  object\n",
      " 6   nn_indices           10227 non-null  object\n",
      " 7   nn_scores            10227 non-null  object\n",
      " 8   reflections          10227 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 719.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "# Remove the first 6227 rows\n",
    "df = dataset.iloc[10210:]\n",
    "\n",
    "# Verify the shape of the DataFrame\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17 entries, 10210 to 10226\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   instruction          17 non-null     object\n",
      " 1   model_name           17 non-null     object\n",
      " 2   generation           17 non-null     object\n",
      " 3   distilabel_metadata  17 non-null     object\n",
      " 4   text                 17 non-null     object\n",
      " 5   embedding            17 non-null     object\n",
      " 6   nn_indices           17 non-null     object\n",
      " 7   nn_scores            17 non-null     object\n",
      " 8   reflections          17 non-null     object\n",
      "dtypes: object(9)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>model_name</th>\n",
       "      <th>generation</th>\n",
       "      <th>distilabel_metadata</th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>nn_indices</th>\n",
       "      <th>nn_scores</th>\n",
       "      <th>reflections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Create a thinking map of the benefits and draw...</td>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>&lt;thinking&gt;\\nI need to think about the context ...</td>\n",
       "      <td>{'raw_output_text_generation_0': '&lt;thinking&gt;\n",
       "I...</td>\n",
       "      <td>[{'content': 'Create a thinking map of the ben...</td>\n",
       "      <td>[-0.04562043026089668, 0.020021433010697365, 0...</td>\n",
       "      <td>[5381]</td>\n",
       "      <td>[0.8502514362335205]</td>\n",
       "      <td>[What are the benefits of purchasing an Apple ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              instruction  \\\n",
       "count                                                  17   \n",
       "unique                                                 17   \n",
       "top     Create a thinking map of the benefits and draw...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                    model_name  \\\n",
       "count                                       17   \n",
       "unique                                       1   \n",
       "top     sentence-transformers/all-MiniLM-L6-v2   \n",
       "freq                                        17   \n",
       "\n",
       "                                               generation  \\\n",
       "count                                                  17   \n",
       "unique                                                 17   \n",
       "top     <thinking>\\nI need to think about the context ...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                      distilabel_metadata  \\\n",
       "count                                                  17   \n",
       "unique                                                 17   \n",
       "top     {'raw_output_text_generation_0': '<thinking>\n",
       "I...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                                     text  \\\n",
       "count                                                  17   \n",
       "unique                                                 17   \n",
       "top     [{'content': 'Create a thinking map of the ben...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                                embedding nn_indices  \\\n",
       "count                                                  17         17   \n",
       "unique                                                 17         17   \n",
       "top     [-0.04562043026089668, 0.020021433010697365, 0...     [5381]   \n",
       "freq                                                    1          1   \n",
       "\n",
       "                   nn_scores  \\\n",
       "count                     17   \n",
       "unique                    17   \n",
       "top     [0.8502514362335205]   \n",
       "freq                       1   \n",
       "\n",
       "                                              reflections  \n",
       "count                                                  17  \n",
       "unique                                                 17  \n",
       "top     [What are the benefits of purchasing an Apple ...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['instruction'].astype(str).tolist()  # Convert to string and then to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Initialize the Tokenizer\n",
    "token = Tokenizer()\n",
    "\n",
    "# Fit the Tokenizer on the text data\n",
    "token.fit_on_texts(texts)\n",
    "\n",
    "# Get the total number of words\n",
    "total_words = len(token.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 484\n"
     ]
    }
   ],
   "source": [
    "print(\"Total words:\", total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = []\n",
    "seq_length = 10  # You can adjust this for longer sequences\n",
    "sequence = token.texts_to_sequences([texts])[0] \n",
    "for i in range(seq_length, len(sequence)):\n",
    "    n_gram_seq = sequence[i-seq_length:i+1]\n",
    "    n_grams.append(n_gram_seq)\n",
    "\n",
    "n_grams = np.array(n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [2, 3, 4], [3, 4, 5]]\n"
     ]
    }
   ],
   "source": [
    "def generate_n_grams(sequence, n):\n",
    "    n_grams = []\n",
    "    for i in range(len(sequence) - n + 1):\n",
    "        n_grams.append(sequence[i:i+n])\n",
    "    return n_grams\n",
    "\n",
    "# Example input\n",
    "sequence = [1, 2, 3, 4, 5]  # Replace with your actual sequence\n",
    "n = 3  # The value of 'n' for n-grams\n",
    "\n",
    "n_grams = generate_n_grams(sequence, n)\n",
    "print(n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [[1 2]\n",
      " [2 3]\n",
      " [3 4]]\n",
      "y: [3 4 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert the list of n-grams to a NumPy array for easier slicing\n",
    "n_grams_array = np.array([[1, 2, 3], [2, 3, 4], [3, 4, 5]])\n",
    "\n",
    "# Split into X (input) and y (target)\n",
    "X = n_grams_array[:, :-1]  # Take all but the last element of each n-gram\n",
    "y = n_grams_array[:, -1]   # Take the last element as the target\n",
    "\n",
    "print(\"X:\", X)\n",
    "print(\"y:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Defining the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=64))  # Embedding layer\n",
    "model.add(LSTM(64))  # Replaced SimpleRNN with LSTM\n",
    "model.add(Dense(10, activation='softmax'))  # Output layer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add(Embedding(total_words, 50, input_length=seq_length))\n",
    "#model.add(SimpleRNN(150, return_sequences=False))  \n",
    "#model.add(Dense(100, activation='relu'))\n",
    "#model.add(Dense(total_words, activation='softmax'))\n",
    "#Replace simpleRNN with GRU\n",
    "#from tensorflow.keras.layers import GRU\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(total_words, 50, input_length=seq_length))\n",
    "# model.add(GRU(150, return_sequences=False))  # Replace SimpleRNN with GRU\n",
    "# model.add(Dense(100, activation='relu'))\n",
    "# model.add(Dense(total_words, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the benefits of that what i what is what the what\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def generate_text(seed_text, next_words=50, temperature=1.0):\n",
    "    for _ in range(next_words):\n",
    "        token_list = token.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=seq_length, padding='pre')\n",
    "        \n",
    "        # Get model predictions\n",
    "        predictions = model.predict(token_list, verbose=0)\n",
    "        \n",
    "        # Apply temperature sampling to the predictions\n",
    "        predictions = predictions.astype('float64')\n",
    "        predictions = np.log(predictions + 1e-7) / temperature\n",
    "        exp_preds = np.exp(predictions)\n",
    "        predictions = exp_preds / np.sum(exp_preds)\n",
    "        \n",
    "        # Choose the next word using a probability distribution\n",
    "        predicted = np.random.choice(len(predictions[0]), p=predictions[0])\n",
    "        output_word = token.index_word.get(predicted, '')\n",
    "        \n",
    "        # If no valid word is found, stop generating further\n",
    "        if output_word == '' or (len(seed_text.split()) > 1 and seed_text.split()[-1] == output_word):\n",
    "            continue\n",
    "        \n",
    "        seed_text += \" \" + output_word\n",
    "    \n",
    "    return seed_text\n",
    "\n",
    "# Generate new text\n",
    "seed_text = \"What are the benefits of\"\n",
    "print(generate_text(seed_text, next_words=10, temperature=1.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
